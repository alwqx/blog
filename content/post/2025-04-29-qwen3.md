---
title: "qwen3 系列模型发布，深度思考，快速响应"
description:
date: 2025-04-29T05:59:48+08:00
image:
math:
license:
hidden: false
comments: true
draft: false
categories:
  - 编程
tags:
  - 大模型
---

## qwen3

### 概览

1. 分为密集模型架构 (0.6B/1.7B/4B/8B/14B/32B) 和混合专家架构 (30B-A3B/235B-A22B)
2. 混合思维模式：支持开启/关闭推理能力即`思考模式`和`非思考模式`，使用户能够根据具体任务控制模型进行`思考的程度`
3. 多语言能力：119 种语言和方言
4. 增强 Agent 能力：优化 Qwen3 模型的 Agent 和 代码能力，同时加强对 MCP 的支持

### 架构

密集模型
| Models | Layers | Heads (Q / KV) | Tie Embedding | Context Length |
| :--------- | :----- | :------------- | :------------ | :------------- |
| Qwen3-0.6B | 28 | 16 / 8 | Yes | 32K |
| Qwen3-1.7B | 28 | 16 / 8 | Yes | 32K |
| Qwen3-4B | 36 | 32 / 8 | Yes | 32K |
| Qwen3-8B | 36 | 32 / 8 | No | 128K |
| Qwen3-14B | 40 | 40 / 8 | No | 128K |
| Qwen3-32B | 64 | 64 / 8 | No | 128K |

MoE 模型

| Models          | Layers | Heads (Q / KV) | # Experts (Total / Activated) | Context Length |
| :-------------- | :----- | :------------- | :---------------------------- | :------------- |
| Qwen3-30B-A3B   | 48     | 32 / 4         | 128 / 8                       | 128K           |
| Qwen3-235B-A22B | 94     | 64 / 4         | 128 / 8                       | 128K           |

### 基准测试

从官方公布的基准测试看，

> 旗舰模型`Qwen3-235B-A22B`在`代码`、`数学`、`通用能力`等基准测试中，与 DeepSeek-R1、o1、o3-mini、Grok-3 和 Gemini-2.5-Pro 等顶级模型相比，表现出极具竞争力的结果。此外，小型 MoE 模型 `Qwen3-30B-A3B` 的激活参数数量是 QwQ-32B 的 10%，表现更胜一筹，甚至像 Qwen3-4B 这样的小模型也能匹敌 Qwen2.5-72B-Instruct 的性能。

![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-235a22.jpg)

![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-30a3.jpg)

### 训练

Qwen3 使用约 36 万亿 Token，在预训练阶段分为 3 步：

1. 模型在超过 30 万亿个 token 上进行了预训练，上下文长度为 4K token。这一阶段为模型提供了基本的语言技能和通用知识
2. 增加知识密集型数据（如 STEM、编程和推理任务）的比例来改进数据集，随后模型又在额外的 5 万亿个 token 上进行了预训练
3. 使用高质量的长上下文数据将上下文长度扩展到 32K token

在后训练分为 4 步

1. 长思维链冷启动：使用多样的的长思维链数据对模型进行了微调，涵盖了数学、代码、逻辑推理和 STEM 问题等多种任务和领域。这一过程旨在为模型配备基本的推理能力
2. 长思维链强化学习：重点在`大规模强化学习`，利用基于规则的奖励来增强模型的探索和钻研能力
3. 思维模式融合：将非思考模式整合到思考模型中
4. 通用强化学习：在 20 多个通用领域的任务上应用了强化学习，以进一步增强模型的通用能力并纠正不良行为

![](https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/post-training.png)

## 使用 qwen3

### 升级 ollama

**qwen3 模型需要 ollama v0.6.6 或更高版本**，先把 Linux 上的 ollama 升级到 v0.6.6:

```shell
wget https://github.com/ollama/ollama/releases/download/v0.6.6/ollama-linux-amd64.tgz
sudo systemctl stop ollama
sudo rm -rf /usr/lib/ollama
sudo tar -C /usr -xzf ollama-linux-amd64.tgz
sudo systemctl start ollama
```

升级完后，下载 `qwen3:8b`模型，大小在 5.2G

```shell
$ ollama pull qwen3:8b
pulling manifest
pulling a3de86cd1c13: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 5.2 GB
pulling eb4402837c78: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 1.5 KB
pulling d18a5cc71b84: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████▏  11 KB
pulling cff3f395ef37: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████▏  120 B
pulling 05a61d37b084: 100% ▕████████████████████████████████████████████████████████████████████████████████████████████████████████▏  487 B
verifying sha256 digest
writing manifest
success
```

配置好模型后，在 LobeChat 中使用 `qwen3:8b` 看下实际效果：

在内容分类方面，DeepSeek-R1:14B 和 qwen3:8b 旗鼓相当。

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/LobeChat_DeepSeek-内容分类助手_r1_2025-04-29.2yyk57cwwu.webp)

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/LobeChat_DeepSeek-内容分类助手_qwen3_2025-04-29.2obqc1xorh.webp)

在内容分类方面，DeepSeek-R1:14B 吊打 qwen3:8b。

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/LobeChat_宣传标语生成_r1_2025-04-29.8dx2nms2ak.webp)

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/LobeChat_宣传标语生成_qwen3_2025-04-29.7i0l86idui.webp)

总的来说各有千秋，要根据实际效果选择模型。
