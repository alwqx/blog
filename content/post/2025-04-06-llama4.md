---
title: "Llama4"
description:
date: 2025-04-06T09:29:49+08:00
image:
math:
license:
hidden: false
comments: true
draft: false
categories:
  - 编程
tags:
  - 大模型
---

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/llama4-release.67xn56wajx.webp)

## 要点

1. 混合专家架构，原生支持多模态
2. 发布 `Llama 4 Scout`和`Llama 4 Maverick`两款原生多模态大模型
3. **支持 1000 万 Token 上下文**，开辟了无限可能，包括多文档总结、解析大量用户活动以执行个性化任务以及在庞大的代码库上进行推理
4. Llama 4 Scout 有 17B 活跃参数，配备了 16 位专家，是同类中最好的多模态模型。可以完全嵌入到一个 NVIDIA H100 GPU 中运行
5. Llama 4 Maverick 同样有 17B 个活跃参数，`但拥有 128 位专家`。它在广泛的基准测试中超越了 GPT-4o 和 Gemini 2.0 Flash，**并且在推理能力和编程等任务上与 DeepSeek v3 相比仅需不到一半的活跃参数就能达到相似的表现**
6. Llama 4 Scout 和 Llama 4 Maverick 都是从 Llama 4 Behemoth 蒸馏而来，Llama 4 Behemoth 有 288B 参数，还在训练中，拥有 16 位专家，是目前最强大的模型之一，在多个 STEM 基准测试上超越了 GPT-4.5、Claude Sonnet 3.7 和 Gemini 2.0 Pro

## 改进

Llama 4 系列模型，首次采用混合专家架构 (mixture of experts MoE), 单个 Token 仅激活总参数的一小部分。Llama 4 Maverick 可以在单个 NVIDIA H100 DGX 主机上轻松部署，或者使用分布式推理以实现最大效率。

Llama 4 系列模型设计时考虑了`原生的多模态特性`，并采用了`早期融合技术`，这使得文本与视觉 Token 能够无缝集成到统一的模型架构中。

我们开发了一种称为“MetaP”的训练技术，可以设置关键的模型超参数，如分层学习速率和初始化尺度。

Llama 4 系列模型通过预训练 200 种语言，包括每种超过 10 亿个 Token 的语言，并且整体上比 Llama 3 多出 10 倍的多语言令牌，从而支持了开源微调能力。

面临的最大挑战是如何在多种输入模态、推理能力和对话能力之间保持平衡。我们通过精心设计的课程策略解决了这个问题，该策略不牺牲与单个模态专家模型相比的表现。对于混合模态处理，我们采用了不同的后端训练流程：轻量级监督微调（SFT）> 在线强化学习（RL）> 轻量级直接偏好优化（DPO）。

## 基准测试

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/llama4-scout-bench.92qbaz5ccf.webp)

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/llama4-mavic-bench.sz4mrb072.webp)

![](https://github.com/alwqx/picx-images-hosting/raw/master/blog/2025/llama4-behemonth-bench.9dd544kkhp.webp)
